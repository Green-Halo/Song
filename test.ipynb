{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#glue_tasks = [\"sst2\", \"mrpc\", \"qqp\", \"mnli\", \"qnli\", \"rte\", \"wnli\"]\n",
    "glue_tasks = [\"sst2\"]\n",
    "datasets = {}\n",
    "\n",
    "# 加载所有的 GLUE 任务数据集\n",
    "for task in glue_tasks:\n",
    "    datasets[task] = load_dataset(\"glue\", task,split=\"train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt 用于控制模型输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_dic={\n",
    "    \"sst2\":\"\"\"In the following conversations, predict the sentiment of the given sentence and output 0  \n",
    "    if it is negative and 1 if it is positive. No analyses or explanations.Only respond with 0 or 1.\"\"\"\n",
    "}\n",
    "for key in glue_tasks:\n",
    "    if key == \"mrpc\":\n",
    "        prompt_dic[key] = \"\"\"\n",
    "        Prompt:\n",
    "        In the following conversations, determine whether the two sentences given are equivalent, \n",
    "        and return 1 if they are, or 0 if they are not. No analyses or explanations.Only respond with 0, 1, or 2.\n",
    "        \"\"\"\n",
    "        \n",
    "    elif key == \"qqp\":\n",
    "        prompt_dic[key] = \"\"\"\n",
    "        Prompt:\n",
    "        In the following conversations, determine whether a pair of questions are semantically equivalent, \n",
    "        and return 1 if they are, or 0 if they are not. You can only return 0 or 1.\n",
    "        \"\"\"\n",
    "        \n",
    "    elif key == \"mnli\":\n",
    "        prompt_dic[key]=\"\"\"\n",
    "        Prompt:\n",
    "        Given a premise sentence and a hypothesis sentence, determine the relationship between the two. The options are:\n",
    "        0 if the premise entails the hypothesis\n",
    "        1 if the relationship is neutral\n",
    "        2 if the hypothesis contradicts the premise\n",
    "        Here are your sentences to evaluate:\n",
    "        Premise: [Insert Premise Sentence Here]\n",
    "        Hypothesis: [Insert Hypothesis Sentence Here]\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    elif key==\"qnli\":\n",
    "        prompt_dic[key] = \"\"\"\n",
    "        Prompt:\n",
    "        Given a question and a sentence, determine whether the sentence contains the answer to the question. The options are:\n",
    "        0 if the sentence contains the answer\n",
    "        1 if the sentence does not contains the answer\n",
    "        Here are your sentences to evaluate:\n",
    "        question: [Insert Question Here]\n",
    "        sentence: [Insert Sentence Here]\n",
    "        No analyses or explanations.Only respond with 0, 1, or 2.\n",
    "        \"\"\"\n",
    "    elif key==\"rte\":\n",
    "        prompt_dic[key] =\"\"\"\n",
    "        Prompt:\n",
    "        Given two sentences, determine whether two sentences are entailments. The options are:\n",
    "        0 if the sentences are entailments\n",
    "        1 if the sentences are not entailments\n",
    "        Here are your sentences to evaluate:\n",
    "        sentence1: [Insert Sentence Here]\n",
    "        sentence2: [Insert Sentence Here]\n",
    "        No analyses or explanations.Only respond with 0 or 1.\n",
    "        \"\"\"\n",
    "    elif key==\"wnli\":\n",
    "        prompt_dic[key] = \"\"\"\n",
    "        Prompt:\n",
    "        Given a question and sentences, determine whether the sentences contain the answer to the question. The options are:\n",
    "        0 if the sentence contains the answer\n",
    "        1 if the sentence does not contains the answer\n",
    "        Here are your sentences to evaluate:\n",
    "        question: [Insert Question Here]\n",
    "        sentences: [Insert Sentence Here]\n",
    "        No analyses or explanations.Only respond with 0 or 1.\n",
    "        \"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Llama-3.1-8B-Instruct_llamacpp_Q4_K_M.gguf\"\n",
    "model_path = f\"/home/syd/Code/Llama/llama.cpp/models/Quantized_models/Llama-3.1-8B-Instruct-llamacpp/{model_name}\"\n",
    "llama_path = \"/home/syd/Code/Llama/llama.cpp.gpu/llama.cpp/llama-cli\"\n",
    "\n",
    "with open(f\"{model_name}.txt\",\"w\") as f:\n",
    "    process = subprocess.Popen(\n",
    "        [llama_path,'-m',model_path,'-cnv'],\n",
    "        stdin=subprocess.PIPE,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "    process.stdin.write(prompt_dic[\"sst2\"] + '\\n')\n",
    "    process.stdin.flush()  # 确保输入被立即发送到模型\n",
    "    \n",
    "    output = process.stdout.readline().strip() # 读取一行输出并去除首尾空白\n",
    "    for i in range(3):\n",
    "        process.stdin.write(datasets[\"sst2\"][i][\"sentence\"]+'\\n')\n",
    "        process.stdin.flush()\n",
    "        output = process.stdout.readline().strip()\n",
    "        f.write(datasets[\"sst2\"][i][\"sentence\"]+' '+output+'\\n')\n",
    "    \n",
    "    error = process.stderr.readline().strip()\n",
    "    if error:\n",
    "        print(f\"Error for input {error}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GreenLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
